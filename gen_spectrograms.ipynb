{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating spectrograms from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIPS_PATH = Path(\"wav_clips\")  # Path module is machine independent\n",
    "SAVE_IMAGE_PATH = Path(\"model_test_train/train\")\n",
    "\n",
    "# Configure these as you wish, currently they are equal to the default values in  the function signature of save_spectrogram_image\n",
    "SAMPLING_RATE = 48000  # gemma's improved sampling rate\n",
    "FFT_NUM = 512  # fft number\n",
    "DPI = 96  # dots per inch\n",
    "MAX_FREQ = 22000\n",
    "MIN_FREQ = 3000\n",
    "IMAGE_SIZE = (413, 202)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spectrogram_image(\n",
    "    input_path,\n",
    "    output_path,\n",
    "    image_name,\n",
    "    sampling_rate=48000,\n",
    "    n_fft=512,\n",
    "    dpi=96,\n",
    "    max_freq=22000,\n",
    "    min_freq=3000,\n",
    "    img_size=(413, 202),\n",
    "):\n",
    "    \"\"\"\n",
    "    This function takes in the above parameters and\n",
    "    generates a spectrogram from a given sample recording and\n",
    "    saves the spectrogram image\n",
    "    \"\"\"\n",
    "    f_step = sampling_rate / n_fft\n",
    "    min_bin = int(min_freq / f_step)\n",
    "    max_bin = int(max_freq / f_step)\n",
    "\n",
    "    # Generate image\n",
    "    x, sr = librosa.load(input_path, sr=sampling_rate)\n",
    "    X = librosa.stft(x, n_fft=n_fft)  # Apply fourier transform\n",
    "    X = X[min_bin:max_bin, :]  # Crop image vertically (frequency axis) from min_bin to max_bin\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))  # Convert amplitude spectrogram to dB-scaled spec\n",
    "    fig = plt.figure(\n",
    "        frameon=False, figsize=(img_size[0] / dpi, img_size[1] / dpi), dpi=dpi\n",
    "    )  # Reduce image\n",
    "    ax = plt.Axes(fig, [0.0, 0.0, 1.0, 1.0])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    librosa.display.specshow(Xdb, cmap=\"gray_r\", sr=sr, x_axis=\"time\", y_axis=\"hz\")\n",
    "\n",
    "    # Save image\n",
    "    fig.savefig(os.path.join(output_path, image_name + \".png\"))\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# File system dependent code\n",
    "def find_clips_local(root_path):\n",
    "    # Assuming they're all directories\n",
    "    for sub_dir_name in os.listdir(root_path):\n",
    "        print(\"Starting  - \" + sub_dir_name + \" ------------\")\n",
    "        path_to_wavs = os.path.join(root_path, sub_dir_name)\n",
    "        print(\"The path to waveforms is: \" + path_to_wavs)\n",
    "        for wavfile in os.listdir(path_to_wavs):\n",
    "            if wavfile.endswith(\".txt\"):  # Selection tables\n",
    "                continue\n",
    "            yield os.path.join(path_to_wavs, wavfile)\n",
    "        print(\"Finished  -----------------------------------\")\n",
    "\n",
    "\n",
    "def find_clips_moby(root_path):\n",
    "    for file_name in os.listdir(root_path):\n",
    "        print(\"Starting  - \" + file_name + \" ------------\")\n",
    "        yield os.path.join(root_path, file_name)\n",
    "    print(\"Finished  -----------------------------------\")\n",
    "\n",
    "\n",
    "def create_storage_for_images(directory_to_store_images):\n",
    "    if os.path.exists(directory_to_store_images):\n",
    "        shutil.rmtree(directory_to_store_images)\n",
    "    os.makedirs(directory_to_store_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executable code\n",
    "create_storage_for_images(SAVE_IMAGE_PATH)\n",
    "counter = 1\n",
    "for clip_path in find_clips_local(CLIPS_PATH):\n",
    "    save_spectrogram_image(clip_path, SAVE_IMAGE_PATH, str(counter))\n",
    "    counter += 1\n",
    "print(\"All images have been created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources and commands:\n",
    "\n",
    "- `find ./train/bottlenose/ -maxdepth 1 -type f | head -n5 | xargs -d '\\n' rm -f --`\n",
    "- `find ./train/bottlenose/ -maxdepth 1 -type f | head -n5 | xargs cp -t ./test/bottlenose/`\n",
    "\n",
    "- https://www.tensorflow.org/tutorials/images/cnn\n",
    "- https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/\n",
    "- https://vijayabhaskar96.medium.com/-tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720 "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "039371b77139fa2b9bd518eca1b62ab7d3ddf0505b49296a18c58435d742de7a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('dolphins': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
